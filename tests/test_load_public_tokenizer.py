from typing import List

import pytest

from src.jptranstokenizer import JapaneseTransformerTokenizer


@pytest.mark.parametrize(
    "pretrained_model, lst_tokens",
    [
        (
            "cl-tohoku/bert-base-japanese",
            [
                [
                    "未来",
                    "科学",
                    "部",
                    "で",
                    "コンビニ",
                    "店員",
                    "に",
                    "なり",
                    "きっ",
                    "て",
                    "お",
                    "##釣",
                    "##り",
                    "を",
                    "返し",
                    "て",
                    "いこ",
                    "う",
                    "!",
                ],
                ["外国", "人", "##参", "政権"],
                ["魔法", "少女", "リ", "##リカル", "な", "の", "は"],
                [
                    "[CLS]",
                    "国境",
                    "の",
                    "[MASK]",
                    "トンネル",
                    "を",
                    "抜ける",
                    "と",
                    "[UNK]",
                    "で",
                    "あっ",
                    "た",
                    "。",
                    "[SEP]",
                ],
            ],
        ),
        (
            "cl-tohoku/bert-base-japanese-v2",
            [
                [
                    "未来",
                    "科学",
                    "部",
                    "で",
                    "コンビニ",
                    "店員",
                    "に",
                    "なり",
                    "きっ",
                    "て",
                    "お",
                    "釣り",
                    "を",
                    "返し",
                    "て",
                    "いこう",
                    "!",
                ],
                ["外国", "人", "##参", "政権"],
                ["魔法", "少女", "リリ", "##カル", "な", "の", "は"],
                [
                    "[CLS]",
                    "国境",
                    "の",
                    "[MASK]",
                    "トンネル",
                    "を",
                    "抜ける",
                    "と",
                    "[UNK]",
                    "で",
                    "あっ",
                    "た",
                    "。",
                    "[SEP]",
                ],
                [
                    "[CLS]",
                    "国境",
                    "の",
                    "[MASK]",
                    "トンネル",
                    "を",
                    "抜ける",
                    "と",
                    "[UNK]",
                    "で",
                    "あっ",
                    "た",
                    "。",
                    "[SEP]",
                ],
            ],
        ),
        (
            "nlp-waseda/roberta-base-japanese",
            [
                [
                    "▁未来",
                    "▁科学",
                    "▁部",
                    "▁で",
                    "▁コンビニ",
                    "▁店員",
                    "▁に",
                    "▁なり",
                    "き",
                    "って",
                    "▁お",
                    "釣",
                    "り",
                    "▁を",
                    "▁返し",
                    "て",
                    "▁いこう",
                    "▁!",
                ],
                ["▁外国", "▁人", "▁参政", "▁権"],
                ["▁魔法", "▁少女", "▁リ", "リ", "カル", "な", "の", "は"],
                [
                    "[CLS]",
                    "▁国境",
                    "▁の",
                    "[MASK]",
                    "▁トンネル",
                    "▁を",
                    "▁抜ける",
                    "▁と",
                    "[UNK]",
                    "▁であった",
                    "▁。",
                    "[SEP]",
                ],
            ],
        ),
        (
            "ku-nlp/deberta-v2-base-japanese",
            [
                [
                    "未来",
                    "▁科学",
                    "▁部",
                    "▁で",
                    "▁コンビニ",
                    "▁店員",
                    "▁に",
                    "▁なり",
                    "き",
                    "って",
                    "▁お",
                    "釣り",
                    "▁を",
                    "▁返して",
                    "▁いこう",
                    "▁!",
                ],
                ["外国", "▁人", "▁参政", "▁権"],
                ["魔法", "▁少女", "▁リ", "リ", "カル", "な", "の", "は"],
                [
                    "[CLS]",
                    "国",
                    "境",
                    "▁の",
                    "[MASK]",
                    "トン",
                    "ネル",
                    "▁を",
                    "▁抜ける",
                    "▁と",
                    "[UNK]",
                    "であった",
                    "▁。",
                    "[SEP]",
                ],
            ],
        ),
    ],
)
def test_public_tokenizer(pretrained_model: str, lst_tokens: List[List[str]]) -> None:
    lst_input: List[str] = [
        "未来科学部でコンビニ店員になりきってお釣りを返していこう！",
        "外国人参政権",
        "魔法少女リリカルなのは",
        "[CLS]国境の[MASK]トンネルを抜けると[UNK]であった。[SEP]",
    ]
    tokenizer: JapaneseTransformerTokenizer = (
        JapaneseTransformerTokenizer.from_pretrained(pretrained_model)
    )
    for sentence, expected_tokens in zip(lst_input, lst_tokens):
        assert tokenizer.tokenize(sentence) == expected_tokens
